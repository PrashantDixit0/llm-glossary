### Benchmarking Glossary

#### MMLU
Multi-task Language Understanding, is a benchmark designed to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the benchmark more challenging and more similar to how we evaluate humans.

[Read More](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu
)

